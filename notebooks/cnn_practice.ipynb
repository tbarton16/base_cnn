{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbarton16/base_cnn/blob/main/notebooks/cnn_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGnO6rUTubLn"
      },
      "source": [
        "# MNIST CNN Classification\n",
        "In this notebook, we will use PyTorch to make a CNN and train it on MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ch9EU5rGuYil"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuwqO8pINZns"
      },
      "source": [
        "# Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNxqQgPjNdUl"
      },
      "outputs": [],
      "source": [
        "bsz= 10\n",
        "lr = 1e-4\n",
        "n_epochs = 10\n",
        "device =  torch.device('cuda')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM-4HtmvvAQn"
      },
      "source": [
        "## Download MNIST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR7TxBzMvmuN"
      },
      "source": [
        "### Creating the dataset involves 3 steps:\n",
        "\n",
        "\n",
        "1.   Downloading the data from the torchvision repository\n",
        "2.   Applying transforms that convert np images to torch tensors and normalize\n",
        "3.   Splitting the data into a train and validation splits.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5UfGdd6GvhD3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "4925fe07-78c7-4b4c-b9ef-cdc07bdb2675"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f007acec19b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transform = torchvision.transforms.Compose([\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1307\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.3081\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
          ]
        }
      ],
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.ToTensor(),\n",
        "  torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDwiFGs9u6YT"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.MNIST('../data', train=False, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgtKkVT4vZ8n"
      },
      "source": [
        "### Convert the dataset into a `dataloader`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dua1_-pWvR4P"
      },
      "outputs": [],
      "source": [
        "dataloader_train = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size = bsz)\n",
        "dataloader_val = torch.utils.data.DataLoader(validation_dataset, shuffle=True, batch_size = bsz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1_ErOy1wlVV"
      },
      "source": [
        "## Define the CNN architecture\n",
        "\n",
        "> [(W−K+2P)/S]+1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbVa_MuRwp4P",
        "outputId": "712655f5-a891-4dff-de0d-36569499394f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 10])\n"
          ]
        }
      ],
      "source": [
        "class MNIStNN(torch.nn.Module):\n",
        "  \"\"\"Take image tensors and output logits\"\"\"\n",
        "  def __init__(self, n_classes):\n",
        "    \"\"\" Architexture: convolution layers (2) (4x4) \n",
        "                      fc layers (2) \n",
        "                      output layer needs to be n_classes\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.n_classes = n_classes\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=10, kernel_size=4) # input (bsz, 1, 28, 28) -> (bsz, 10, 25, 25)\n",
        "    # [(W−K+2P)/S]+1 = (28 - 4 +  ) / 1  + 1 = 25\n",
        "    # 25 - 4 + 0 /1 + 1 = 22\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=10, out_channels=10, kernel_size=4) # output =(bsz, 10, 22, 22)\n",
        "    self.lin1 = torch.nn.Linear(10* 22 * 22, 256)\n",
        "    self.lin2 = torch.nn.Linear(256, self.n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    first_layer = F.relu(self.conv1(x))\n",
        "    second_layer = F.relu(self.conv2(first_layer))# (bsz, 10, 22, 22)\n",
        "    second_layer_flat = second_layer.reshape((second_layer.shape[0], -1))\n",
        "    fc_1 = F.relu(self.lin1(second_layer_flat))\n",
        "    logits = self.lin2(fc_1)\n",
        "\n",
        "    return logits\n",
        "\n",
        "x = torch.randn(10,1,28,28)\n",
        "tessnet = MNIStNN(10)\n",
        "print(tessnet(x).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAKDMH7BYz2M",
        "outputId": "49747927-d43c-4e0f-b421-b2a0f94b7bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 10])\n"
          ]
        }
      ],
      "source": [
        "class LeNet(torch.nn.Module):\n",
        "  \"\"\" Input tensors and calculate logits\"\"\" \n",
        "  def __init__(self, n_classes):\n",
        "    super().__init__()\n",
        "    self.n_classes = n_classes\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) # input (bsz, 1, 28,28) (bsz, 6, 24, 24)\n",
        "    # [(W−K+2P)/S]+1 (28 - 5)/1 + 1\n",
        "    self.batchnorm = torch.nn.BatchNorm2d(num_features=6 )\n",
        "    self.maxpool = torch.nn.MaxPool2d(kernel_size=2) # (bsz, 6, 12, 12)\n",
        "    self.conv2 =  torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)  # (bsz, 16, 8, 8)\n",
        "    self.batchnorm2 = torch.nn.BatchNorm2d(num_features=16)\n",
        "    self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2) # (bsz, 16, 4, 4)\n",
        "    self.fc0 = torch.nn.Linear(16*4*4, 120)\n",
        "    self.fc1 = torch.nn.Linear(120, 84)\n",
        "    self.fc2 = torch.nn.Linear(84, self.n_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    c1 = self.conv1(x)\n",
        "    bn = self.batchnorm(c1)\n",
        "    mp = self.maxpool(F.relu(bn))\n",
        "    c2 = self.conv2(mp)\n",
        "    bn2 = self.batchnorm2(c2)\n",
        "    mp2 = self.maxpool2(F.relu(bn2))\n",
        "    features_flat = mp2.reshape(mp2.shape[0], -1)\n",
        "    f1 = F.relu(self.fc0(features_flat))\n",
        "    f2 = F.relu(self.fc1(f1))\n",
        "    logits = F.relu(self.fc2(f2))\n",
        "\n",
        "    return logits\n",
        "\n",
        "x = torch.randn(10,1,28,28)\n",
        "tessnet = LeNet(10)\n",
        "print(tessnet(x).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2o2eIxvPe3j"
      },
      "outputs": [],
      "source": [
        "for X, y in dataloader_train:\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCYhW0Y0wqn2"
      },
      "source": [
        "## Training Loop\n",
        "Produce a training loss curve that goes down over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzHX_w88wtFq",
        "outputId": "d37a4777-f57a-438f-e2b8-8de540fa343e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2830557823181152\n",
            "2.2818779945373535\n",
            "1.8800716400146484\n",
            "1.9220125675201416\n",
            "1.0602778196334839\n",
            "1.4282146692276\n",
            "0.9862087965011597\n",
            "1.140547752380371\n",
            "0.3676227033138275\n",
            "0.7402256727218628\n",
            "0.8225216865539551\n",
            "0.48971033096313477\n",
            "0.6303771734237671\n",
            "0.8425195813179016\n",
            "1.0257947444915771\n",
            "0.7063733339309692\n",
            "0.036657899618148804\n",
            "0.4923439621925354\n",
            "1.207017183303833\n",
            "0.39375725388526917\n",
            "0.2620166838169098\n",
            "0.24785736203193665\n",
            "0.05594904348254204\n",
            "0.8471209406852722\n",
            "0.3354804217815399\n",
            "0.7061797380447388\n",
            "0.6105878353118896\n",
            "0.7868552803993225\n",
            "0.31067997217178345\n",
            "0.7378519773483276\n",
            "0.9343346357345581\n",
            "0.6683343052864075\n",
            "0.3322896957397461\n",
            "0.7058837413787842\n",
            "0.7208536863327026\n",
            "0.8561877012252808\n",
            "0.17750653624534607\n",
            "0.5351110696792603\n",
            "0.46925482153892517\n",
            "0.47974032163619995\n",
            "0.7441506385803223\n",
            "0.4224326014518738\n",
            "0.7289177179336548\n",
            "0.4936775267124176\n",
            "0.013891272246837616\n",
            "0.46610814332962036\n",
            "0.7931881546974182\n",
            "0.7409679293632507\n",
            "0.23984161019325256\n",
            "0.937588095664978\n",
            "0.5181482434272766\n",
            "0.37508025765419006\n",
            "0.9131830930709839\n",
            "1.023576021194458\n",
            "0.44451603293418884\n",
            "0.7157229781150818\n",
            "0.24075810611248016\n",
            "0.7477538585662842\n",
            "0.757651686668396\n",
            "0.5161660313606262\n",
            "1.3376867771148682\n",
            "0.47879862785339355\n",
            "0.22854578495025635\n",
            "0.7125805616378784\n",
            "0.9473955035209656\n",
            "0.489694207906723\n",
            "0.4956859052181244\n",
            "0.7361866235733032\n",
            "0.7206340432167053\n",
            "0.58623868227005\n",
            "0.47051382064819336\n",
            "0.27602940797805786\n",
            "0.48129311203956604\n",
            "0.6946619153022766\n",
            "0.3789123594760895\n",
            "0.4918895363807678\n",
            "0.30947592854499817\n",
            "0.907008171081543\n",
            "1.3420517444610596\n",
            "0.04923323541879654\n",
            "0.12897078692913055\n",
            "0.47765153646469116\n",
            "0.7182115912437439\n",
            "0.46265530586242676\n",
            "0.6917003393173218\n",
            "0.46322450041770935\n",
            "0.2431817501783371\n",
            "0.29578402638435364\n",
            "0.6941694021224976\n",
            "0.6915809512138367\n",
            "1.0066349506378174\n",
            "0.6042060256004333\n",
            "0.7494146823883057\n",
            "0.9895656704902649\n",
            "0.12008240073919296\n",
            "0.6979972720146179\n",
            "0.7669530510902405\n",
            "0.48619166016578674\n",
            "0.7538038492202759\n",
            "0.507190465927124\n",
            "0.4642786979675293\n",
            "0.921177864074707\n",
            "0.9642595052719116\n",
            "0.48638859391212463\n",
            "0.8203264474868774\n",
            "0.3704318106174469\n",
            "0.2550358474254608\n",
            "0.7150463461875916\n",
            "0.5580666661262512\n",
            "0.025897491723299026\n",
            "0.08653239160776138\n",
            "0.0040152245201170444\n",
            "0.486179918050766\n",
            "1.1969667673110962\n",
            "0.31948956847190857\n",
            "0.9266045689582825\n",
            "0.6927868723869324\n",
            "0.30317336320877075\n",
            "0.7118384838104248\n",
            "0.5565085411071777\n",
            "0.2453203946352005\n",
            "0.24894587695598602\n",
            "0.5127384662628174\n",
            "0.9430166482925415\n",
            "0.8809685707092285\n",
            "0.6913141012191772\n",
            "0.25134986639022827\n",
            "0.24541108310222626\n",
            "0.6951264142990112\n",
            "1.248746633529663\n",
            "0.008147316053509712\n",
            "0.5621241331100464\n",
            "0.46808767318725586\n",
            "0.009430200792849064\n",
            "0.9916415214538574\n",
            "0.5580140352249146\n",
            "0.6244655847549438\n",
            "0.5668323636054993\n",
            "0.6657443046569824\n",
            "0.036289967596530914\n",
            "0.31334570050239563\n",
            "0.569668173789978\n",
            "0.7034013271331787\n",
            "0.6915643215179443\n",
            "0.017784511670470238\n",
            "0.3806232810020447\n",
            "0.5219956040382385\n",
            "0.23820912837982178\n",
            "0.7209265232086182\n",
            "0.46171608567237854\n",
            "0.8257573843002319\n",
            "0.7086660861968994\n",
            "0.5085898041725159\n",
            "0.4613025188446045\n",
            "0.5299180150032043\n",
            "0.2500839829444885\n",
            "0.6544476747512817\n",
            "0.9556012153625488\n",
            "0.4628164768218994\n",
            "0.0013856226578354836\n",
            "0.23790590465068817\n",
            "0.24446937441825867\n",
            "0.9261444211006165\n",
            "1.1750568151474\n",
            "0.004416586831212044\n",
            "0.0366571843624115\n",
            "0.6918209791183472\n",
            "0.6994749903678894\n",
            "0.7357599139213562\n",
            "0.46314042806625366\n",
            "0.4739477038383484\n",
            "0.9217510223388672\n",
            "0.46219682693481445\n",
            "0.14360983669757843\n",
            "0.9223965406417847\n",
            "0.4611082077026367\n",
            "0.702418863773346\n",
            "1.0780367851257324\n",
            "0.27242201566696167\n",
            "1.3384236097335815\n",
            "0.23075440526008606\n",
            "0.7331939935684204\n",
            "0.7083183526992798\n",
            "0.7058537602424622\n",
            "0.0015874095261096954\n",
            "0.6419830322265625\n",
            "0.037637386471033096\n",
            "0.7058757543563843\n",
            "0.4767264425754547\n",
            "0.23401442170143127\n",
            "0.7231836318969727\n",
            "0.6946767568588257\n",
            "0.6974192261695862\n",
            "0.021900523453950882\n",
            "0.010567841120064259\n",
            "0.05651552602648735\n",
            "0.6975623369216919\n",
            "0.6817244291305542\n",
            "0.48394203186035156\n",
            "0.2528795301914215\n",
            "0.466940313577652\n",
            "0.002226960612460971\n",
            "0.23168237507343292\n",
            "0.7037486433982849\n",
            "0.46359914541244507\n",
            "0.7690938711166382\n",
            "0.6946681141853333\n",
            "0.009612753055989742\n",
            "0.6935452222824097\n",
            "0.46741408109664917\n",
            "0.6967092752456665\n",
            "0.5043365955352783\n",
            "0.844887375831604\n",
            "0.4606960713863373\n",
            "0.46283331513404846\n",
            "0.49801263213157654\n",
            "1.1704000234603882\n",
            "0.7034705877304077\n",
            "0.46124234795570374\n",
            "0.5114010572433472\n",
            "1.3796215057373047\n",
            "0.48325881361961365\n",
            "0.9253050088882446\n",
            "0.9766191244125366\n",
            "0.38066568970680237\n",
            "0.247953861951828\n",
            "0.4623648524284363\n",
            "0.24284395575523376\n",
            "0.3637419044971466\n",
            "0.4973812997341156\n",
            "0.26655298471450806\n",
            "0.233821839094162\n",
            "0.230503648519516\n",
            "0.4756126403808594\n",
            "0.6781566739082336\n",
            "1.250199556350708\n",
            "0.6993240714073181\n",
            "0.5890472531318665\n",
            "0.23686881363391876\n",
            "0.4612122178077698\n",
            "0.2441612184047699\n",
            "1.1515167951583862\n",
            "1.1523761749267578\n",
            "0.708538830280304\n",
            "0.23665420711040497\n",
            "0.2332383096218109\n",
            "0.4126821458339691\n",
            "0.4716550409793854\n",
            "0.24378514289855957\n",
            "0.6925176382064819\n",
            "0.46461883187294006\n",
            "0.46923843026161194\n",
            "0.6911337971687317\n",
            "0.2347501963376999\n",
            "0.16990628838539124\n",
            "0.6926476955413818\n",
            "0.465508371591568\n",
            "0.31427446007728577\n",
            "0.2722005844116211\n",
            "0.2311818152666092\n",
            "0.9228574633598328\n",
            "0.49552154541015625\n",
            "0.4816785454750061\n",
            "0.46247607469558716\n",
            "0.695870041847229\n",
            "0.6967148780822754\n",
            "0.28613319993019104\n",
            "0.5063775777816772\n",
            "0.5494266748428345\n",
            "0.9211385846138\n",
            "0.9268512725830078\n",
            "0.4648551046848297\n",
            "0.9248663783073425\n",
            "0.46871671080589294\n",
            "0.23174746334552765\n",
            "0.2669784426689148\n",
            "0.6911388635635376\n",
            "0.7342687845230103\n",
            "1.598230242729187\n",
            "0.4669114053249359\n",
            "0.462719589471817\n",
            "0.2334567755460739\n",
            "0.23101933300495148\n",
            "0.692718505859375\n",
            "0.46906885504722595\n",
            "0.6910701990127563\n",
            "0.24649450182914734\n",
            "0.2944861054420471\n",
            "0.7343639135360718\n",
            "0.23855412006378174\n",
            "0.8328279256820679\n",
            "0.46182432770729065\n",
            "0.92127925157547\n",
            "0.37955984473228455\n",
            "0.47269248962402344\n",
            "0.6909750699996948\n",
            "0.46327027678489685\n",
            "0.00031546602258458734\n",
            "0.23272109031677246\n",
            "0.6957281231880188\n",
            "0.05335129052400589\n",
            "0.6945229768753052\n",
            "0.5339480638504028\n",
            "0.0017110155895352364\n",
            "0.8138378262519836\n",
            "0.4611876904964447\n",
            "0.23729637265205383\n",
            "0.46195173263549805\n",
            "1.1711606979370117\n",
            "0.2313852608203888\n",
            "0.9507719278335571\n",
            "0.9580333828926086\n",
            "0.9223136901855469\n",
            "0.23323583602905273\n",
            "0.0017695631831884384\n",
            "0.698910653591156\n",
            "0.7148865461349487\n",
            "0.6917957663536072\n",
            "0.5282745361328125\n",
            "0.6909877061843872\n",
            "0.4930177330970764\n",
            "1.1520437002182007\n",
            "0.7830777764320374\n",
            "0.692717432975769\n",
            "0.2310546338558197\n",
            "0.013531561009585857\n",
            "0.46089544892311096\n",
            "0.24734556674957275\n",
            "0.6935036778450012\n",
            "0.2461164891719818\n",
            "0.23116645216941833\n",
            "0.4607394337654114\n",
            "0.4610203206539154\n",
            "0.4606827199459076\n",
            "0.6908394694328308\n",
            "0.2455974519252777\n",
            "0.4620491564273834\n",
            "0.7012549638748169\n",
            "0.46170687675476074\n",
            "0.4610561430454254\n",
            "0.92811518907547\n",
            "0.9421414136886597\n",
            "0.47798046469688416\n",
            "1.1613483428955078\n",
            "0.9240623712539673\n",
            "0.9252854585647583\n",
            "0.6517587304115295\n",
            "0.497913122177124\n",
            "0.9223888516426086\n",
            "0.24970643222332\n",
            "0.006048726849257946\n",
            "0.2623911499977112\n",
            "0.692920446395874\n",
            "0.4622229039669037\n",
            "1.1515083312988281\n",
            "0.019863370805978775\n",
            "0.004555060528218746\n",
            "0.6910086870193481\n",
            "0.4625062346458435\n",
            "0.9226015210151672\n",
            "0.6912110447883606\n",
            "0.9211177825927734\n",
            "0.23268528282642365\n",
            "1.1523888111114502\n",
            "0.23353219032287598\n",
            "0.23854084312915802\n",
            "0.6928575038909912\n",
            "0.46327394247055054\n",
            "0.23188607394695282\n",
            "0.6915037631988525\n",
            "0.7407171726226807\n",
            "0.4622719883918762\n",
            "0.6934513449668884\n",
            "0.6910507678985596\n",
            "0.6909032464027405\n",
            "0.34933388233184814\n",
            "0.231548473238945\n",
            "0.23917236924171448\n",
            "0.2891849875450134\n",
            "0.7021929025650024\n",
            "0.690829873085022\n",
            "0.24735668301582336\n",
            "0.23317880928516388\n",
            "0.2532273232936859\n",
            "0.46437788009643555\n",
            "0.8245601654052734\n",
            "0.23354308307170868\n",
            "0.2316444218158722\n",
            "0.0020192910451442003\n",
            "0.7059664130210876\n",
            "0.9210829734802246\n",
            "0.9212938547134399\n",
            "0.6923930644989014\n",
            "0.014476443640887737\n",
            "0.2427119016647339\n",
            "1.8486888408660889\n",
            "0.46070924401283264\n",
            "0.2305653840303421\n",
            "0.6973304748535156\n",
            "0.0009832708165049553\n",
            "0.47316089272499084\n",
            "0.4612404406070709\n",
            "1.151332139968872\n",
            "0.4686312675476074\n",
            "0.46094951033592224\n",
            "0.46129903197288513\n",
            "0.2467011958360672\n",
            "0.46291637420654297\n",
            "0.7604692578315735\n",
            "0.06013348698616028\n",
            "0.2309916913509369\n",
            "0.6908019185066223\n",
            "1.4805433750152588\n",
            "0.23317010700702667\n",
            "0.002238453831523657\n",
            "0.4884558320045471\n",
            "0.025430787354707718\n",
            "0.6909646391868591\n",
            "0.3049772381782532\n",
            "0.23200325667858124\n",
            "0.46101927757263184\n",
            "0.23585852980613708\n",
            "0.935338020324707\n",
            "0.23175621032714844\n",
            "0.32701733708381653\n",
            "0.46869152784347534\n",
            "0.46085625886917114\n",
            "0.4616960883140564\n",
            "0.23083865642547607\n",
            "0.4664086401462555\n",
            "0.9210742712020874\n",
            "0.4021357595920563\n",
            "0.6919645071029663\n",
            "0.697552502155304\n",
            "0.23197729885578156\n",
            "0.4610523283481598\n",
            "0.691389799118042\n",
            "0.008325868286192417\n",
            "0.6912766695022583\n",
            "0.4634253978729248\n",
            "0.9553879499435425\n",
            "0.461636483669281\n",
            "0.6910604238510132\n",
            "1.1516623497009277\n",
            "0.6914838552474976\n",
            "0.921106219291687\n",
            "0.46060609817504883\n",
            "0.46058860421180725\n",
            "0.23349551856517792\n",
            "0.4640793800354004\n",
            "0.4612608551979065\n",
            "0.4628888964653015\n",
            "0.0007684233714826405\n",
            "0.2337034046649933\n",
            "0.23033957183361053\n",
            "0.03002922609448433\n",
            "0.6158686280250549\n",
            "0.25956839323043823\n",
            "0.4614955484867096\n",
            "0.5930922031402588\n",
            "0.23030638694763184\n",
            "0.4612196385860443\n",
            "0.6908911466598511\n",
            "0.6909576654434204\n",
            "0.6962072849273682\n",
            "0.4606093466281891\n",
            "0.4605379104614258\n",
            "0.8758222460746765\n",
            "0.7580955028533936\n",
            "0.23335902392864227\n",
            "0.9211755990982056\n",
            "0.2328033745288849\n",
            "0.6926244497299194\n",
            "0.9378533363342285\n",
            "0.23820669949054718\n",
            "0.23055589199066162\n",
            "0.9896001815795898\n",
            "0.5040356516838074\n",
            "0.6914020776748657\n",
            "0.23144516348838806\n",
            "0.9211978912353516\n",
            "0.7004335522651672\n",
            "0.46160635352134705\n",
            "0.6908995509147644\n",
            "0.9211608171463013\n",
            "0.001465560868382454\n",
            "0.23043087124824524\n",
            "0.464546263217926\n",
            "0.690804123878479\n",
            "0.9211543798446655\n",
            "0.7043901681900024\n",
            "0.012361572124063969\n",
            "1.1557080745697021\n",
            "0.2456570565700531\n",
            "1.1513172388076782\n",
            "0.2327367067337036\n",
            "0.461721807718277\n",
            "0.6930165886878967\n",
            "1.151313066482544\n",
            "0.6927900910377502\n",
            "0.006240483373403549\n",
            "0.4645187258720398\n",
            "0.6946295499801636\n",
            "0.23042726516723633\n",
            "0.47182130813598633\n",
            "0.6987705230712891\n",
            "0.23149065673351288\n",
            "0.003698072861880064\n",
            "0.46241655945777893\n",
            "0.23274724185466766\n",
            "0.3102675974369049\n",
            "0.9598747491836548\n",
            "0.0003391666105017066\n",
            "0.9222261309623718\n",
            "0.4611797332763672\n",
            "0.4638712406158447\n",
            "0.2321208417415619\n",
            "0.4827752709388733\n",
            "0.9284653663635254\n",
            "0.4614296853542328\n",
            "0.4625721871852875\n",
            "0.921186625957489\n",
            "0.23097293078899384\n",
            "0.9211185574531555\n",
            "0.23142719268798828\n",
            "0.4636566638946533\n",
            "0.690822958946228\n",
            "0.23041050136089325\n",
            "0.6910079717636108\n",
            "0.4605332016944885\n",
            "0.3082270324230194\n",
            "0.00986510794609785\n",
            "0.462440550327301\n",
            "0.6945599317550659\n",
            "1.151627540588379\n",
            "0.23110127449035645\n",
            "0.4732216000556946\n",
            "0.23142775893211365\n",
            "1.1513100862503052\n",
            "0.46624284982681274\n",
            "0.23051312565803528\n",
            "0.9211283922195435\n",
            "0.007515032775700092\n",
            "0.1026744693517685\n",
            "0.6909964084625244\n",
            "0.23043903708457947\n",
            "0.6910573244094849\n",
            "0.6909518241882324\n",
            "0.48446354269981384\n",
            "0.9321721792221069\n",
            "0.23042833805084229\n",
            "0.027523955330252647\n",
            "0.4635750651359558\n",
            "0.6907802820205688\n",
            "0.2303016483783722\n",
            "0.4606059193611145\n",
            "0.23068785667419434\n",
            "0.6993116140365601\n",
            "0.4605375826358795\n",
            "0.4610995352268219\n",
            "0.00010116051271324977\n",
            "0.5161966681480408\n",
            "0.46294745802879333\n",
            "0.4605771005153656\n",
            "0.2328856736421585\n",
            "0.46346861124038696\n",
            "1.1513258218765259\n",
            "0.4955991208553314\n",
            "0.4615643620491028\n",
            "0.6915255784988403\n",
            "0.46336036920547485\n",
            "0.2308570146560669\n",
            "1.151445746421814\n",
            "0.2403903752565384\n",
            "0.23236432671546936\n",
            "0.009276664815843105\n",
            "0.000259564898442477\n",
            "0.46074700355529785\n",
            "0.4958510398864746\n",
            "0.9211475253105164\n",
            "0.6914036870002747\n",
            "0.004861786961555481\n",
            "0.03251843899488449\n",
            "0.8241305351257324\n",
            "0.4605942666530609\n",
            "0.23439526557922363\n",
            "0.4606779217720032\n",
            "0.2307695597410202\n",
            "0.9211652874946594\n",
            "0.23107096552848816\n",
            "0.23038756847381592\n",
            "0.9255850911140442\n",
            "0.2378174364566803\n",
            "0.691347062587738\n",
            "5.347305705072358e-05\n",
            "0.6912027597427368\n",
            "0.4633508324623108\n",
            "0.4609456956386566\n",
            "0.23194611072540283\n",
            "0.465308278799057\n",
            "0.23182067275047302\n",
            "0.467438280582428\n",
            "0.693896472454071\n",
            "0.021080749109387398\n",
            "0.23553752899169922\n",
            "0.4676322340965271\n",
            "0.23374848067760468\n",
            "0.49313750863075256\n",
            "0.46068963408470154\n",
            "0.46072903275489807\n"
          ]
        }
      ],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "tessnet = LeNet(10).to(device)\n",
        "optimizer = torch.optim.Adam(tessnet.parameters(), lr=lr)\n",
        "\n",
        "tessnet.train() # some layers behave differently in train or test mode (dropout, batch norm)\n",
        "losses = []\n",
        "for e in range(n_epochs):\n",
        "  for i, batch in enumerate(dataloader_train):\n",
        "    # move minibatch (only) to device\n",
        "    X,y = batch\n",
        "    X, y  = X.to(device), y.to(device)\n",
        "    logits = tessnet(X)\n",
        "    loss = criterion(logits, y)\n",
        "    optimizer.zero_grad() # clears gradients from each node\n",
        "    loss.backward() # performs backprop to find the gradient at each node\n",
        "    optimizer.step() # updates the parameters\n",
        "    if i % 99==0:\n",
        "      print(loss.item())\n",
        "    losses.append(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Pqly3upiXhV7",
        "outputId": "14f973e4-91a7-4c81-e7be-4fed8ee91ced"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f37fbe45d90>]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgc1Zku8PcDGxKWYbMmYzYLcklYMgSIIHCTSUggXLaB3AuZMeQ6hJuMJwTuwGQbGyYmeOwMqwFjBmNsEwzEGC8xBnnBG7ZsZNmSLMmWvEi2JEuyrX1frO3MH10tVbequ6u7q7oWvb/n8eNWdXXVV718derUWUQpBSIi8r6TnA6AiIiswYROROQTTOhERD7BhE5E5BNM6EREPjHGqR2PGzdOpaenO7V7IiJPysvLa1BKpRk951hCT09PR25urlO7JyLyJBGpjPQcq1yIiHyCCZ2IyCeY0ImIfIIJnYjIJ2ImdBG5SEQ2i0iJiBSLyOMG69wsIq0iUqD9m2ZPuEREFImZVi79AH6tlMoXkTMB5InIeqVUSdh6WUqpu60PkYiIzIhZQldKHVNK5WuP2wHsA3CB3YEREVF84qpDF5F0ANcCyDF4+iYRKRSRNSJyVYTXTxaRXBHJra+vjztYcrfNB+pQ3dzldBhEo5bphC4iZwBYDuAJpVRb2NP5ACYopb4O4DUAK422oZSap5TKUEplpKUZdnQiD3v47V2445Usp8MgGrVMJXQRGYtAMn9fKbUi/HmlVJtSqkN7vBrAWBEZZ2mk5AntJ/qdDoFo1DLTykUALACwTyk1K8I6f6OtBxG5Qdtuo5WBEhFRdGZauXwLwCQAe0SkQFv2JICLAUApNRfA/QAeEZF+AN0AJirObUdElFIxE7pSahsAibHOHABzrAqKiIjix56iREQ+wYROROQTTOhERD7BhE5E5BNM6EREPsGETkTkE0zoREQ+4bmEXt9+AttKG9DJLuZERCE8l9BzyhvxfxfkoKal2+lQiIhcxXMJXbROqxxYgIgolOcS+knaIAQKzOhERHqeS+iiJfTBQWfjICJyG88l9OA4YSyhE3nPqxtKkX+k2ekwfMtzCX2oyoX5nMhzXt5wEP/nvz53Ogzf8lxC1+bRYEInIgrjvYSu/c8qFyKiUN5L6KxyISIy5LmEflKwysXhOIiI3MZzCT1Y5zLIIjoRUQjPJfShOnTmcyKiEJ5L6MEqF1a6EBGF8lxCH+opynxORBTCewmdg3MRERnyXkIfarbIjE5EpOfdhO5sGOSgK6etxb1ztjkdBpHreC+ha1UubLY4enX1DqCwutXpMIhcx3sJXSuhd/cOOBsIEZHLeC6hF1W3AACmfVTscCRERO7iuYTecSJQMuecokREoTyX0IPjoRMRUaiYCV1ELhKRzSJSIiLFIvK4wToiIrNFpExEikTkOnvCHb4pSkREocyU0PsB/FopdSWAGwE8KiJXhq1zB4DLtH+TAbxhaZQ6o6mE3tLVi0F2iSUik2ImdKXUMaVUvva4HcA+ABeErXYvgEUqYAeAs0VkvOXRAjhplGT0lq5eXDN9PZ5fd8DpUIjII+KqQxeRdADXAsgJe+oCAFW6v6sxMulTHJq7+gAAa/ceczgSIvIK0wldRM4AsBzAE0qptkR2JiKTRSRXRHLr6+sT2YRutEUid8irbEJFQ6fTYRCZS+giMhaBZP6+UmqFwSo1AC7S/X2htiyEUmqeUipDKZWRlpaWSLyjqg6dvOG+N7Jx84ufOR0GkalWLgJgAYB9SqlZEVZbBeAnWmuXGwG0KqVsqStgAZ2IyNgYE+t8C8AkAHtEpEBb9iSAiwFAKTUXwGoAdwIoA9AF4GHrQw1gs0UiImMxE7pSahsQPYuqwFi2j1oVVDQsoRMRGfNgT9HYGV0pxfHSiWjU8VxCN1NC/84Lm3HN9PX2B0NE5CKeS+hmSuhVTd1o7e5LQTTu0ts/iKzSxJqDEpH3eTChOx2Be72wbj8mLdiJ/CPNTodCRA7wXEIX3hWN6FB9oHNLc2evw5EQkRM8mNCdjoCIyJ08l9DZ9Z+IyJjnEvo5p411OgQiIlfyXEL/ctoZTodAZAulFCc/p6R4LqGzxoX8as6mMlwxbS1valPCPJfQY4xCQORZKwsCA5Q2dp5wOBLyKs8ldJbQiYiMeS6hs5ULEZExzyV0pnMiImPeS+jM6EREhryX0FlGj4hDBhONbt5L6MznMfE9IhqdfJ3Q23pG3xC6RDR6eTChm8/oV//hUxsjISJyF+8ldKcDILIZb4VQojyX0EdbO3T+tkcPjvVPyfJcQh8t3/lRcphEZCHvJXSnA3AxluaJRjfPJXRm9NjYVp9odPJcQmeyIiIy5r2EznxORGTIcwm9pYuD/xMRGfFcQh8YdDoC92L7ZaLRzXMJnVUuJvA98jSelylR3kvoTgdAZBN+tylZ3kvo/NYTERmKmdBFZKGI1InI3gjP3ywirSJSoP2bZn2YIfuzc/NERJ41xsQ6fwIwB8CiKOtkKaXutiSiGJjOiYiMxSyhK6W2AmhKQSxERJQEq+rQbxKRQhFZIyJXRVpJRCaLSK6I5NbX1ye0I1a5EBEZsyKh5wOYoJT6OoDXAKyMtKJSap5SKkMplZGWlpbQzk5iPiciBxyu78DavcedDiOqpBO6UqpNKdWhPV4NYKyIjEs6sgjCx3KZmVmCd7Mr7NodEREA4PsvbcEv3stzOoyozNwUjUpE/gZArVJKicgNCJwkGpOOLOL+Qv9+K6scADDppnS7dklE5AkxE7qILAZwM4BxIlIN4GkAYwFAKTUXwP0AHhGRfgDdACYqZV8n9FPHeK7pPFFcOIQDJSpmQldKPRDj+TkINGtMibNOG5uqXRGlFO/3U7I8V9zleOiRBQt2fIeIRifPJXSKLFjTxaadRKOTbxJ6T9+A0yEQETnKcwk9UuHz2unrDZfbeH/Wk3r7B3H3a1n4vKzB6VCIyGKeS+iRdLOEbkp1cxf21rThqZWGY60RkYf5JqETEY12nkvoo+12H2uMiMgszyX00cKuhip2nR94r4LIeZ5L6GySZw2+i+6lOKsoJchzCZ3Ir9hpjpLFhE5E5BOeS+j6MsyuCk6kREQU5LmErvejudlOh+A5vHdJbqSU4o11C3g6oZtR23bC6RBSzlRNLKtryUUumboaD729y+kwPM9zCT1aI5ecwyPn1ahr77ExGiKyytaDic0zTMM8l9CjmZG5b8QyXsWlBt9nIud5LqGzHXqymHmJ/MpzCZ2swdOie/FqhxLl+4Tul9/GtdM/xa8/LHQ6DLIRLz4pWb5P6OF2H2nG3z2/CR0n+p0OJS7NXX1Ynl8ddR2W7IhGN18l9D01rTHXefHTA6hq6kbBkZYURDSsp28ANS3dKdlXtJIekz6Rf/kqobvZz9/Jxbee3eR0GEN4c5nIf0ZtQjc7ot3h+g5c/vs1ONLYldT+tvl8yjcW/Imc5/uEHuxOfP3MDZi6oijuEe2W51ejp28Qqwpr7AiPiMgyvk/oQfXtJ7B4Z9XQ30oBlz21Gi+uO+BgVNYyc9XBkjSRf/k+oYfXFQf/VAD6BhTmbC5LfVA2i3YVErwpyhp0Iv/xfUK3SrTWIZ8WH8fS3KrIK7gQ74kS+c8YpwOwW6QhOc0O1Wmmzn3yu3kAgB9lXGQ+MJ/iiSK6b/5xAwSCHU/eEnEdNi2lRPk+oYcz21zvuy9sRsaEczH+rC/YHFFquX2+ysrGTlQ0duG7X0lzOhRbjMbhnCl1fF/lEil9xUprlY1dMXtmeplb56/87guf4aGFO50Og8iTfJ/Qww2lMXcXVD2Hs80QOS9mQheRhSJSJyJ7IzwvIjJbRMpEpEhErrM+TOsMt3IZTkD/uqQg5uuYrsxxZ7mfaHQwU0L/E4Dbozx/B4DLtH+TAbyRfFj2MUo4f9kdudOQ327ysSBN5F8xE7pSaiuApiir3AtgkQrYAeBsERlvVYDx+qggeo/OzQe8Nc2VXTcx/XaiIn/Yd6zN6RA8zYo69AsA6BthV2vLRhCRySKSKyK59fX2JNb3dxwJ+TtSidRNJdX9x9twsLY9ZFnwpmVVUzcqGzudCIso5e54NcvpEDwtpTdFlVLzlFIZSqmMtLTUNEsrORp7SF0z9CeAD3YeQVVTcoN16d3+ShZue3lrxOf/WWvnTkQUjRUJvQaAvkfNhdoyV/j9R8WGy59ds9/U68NrJnr7BzFlxR7cP/fzJCMzr3/Q3OWEmasON12ZkDG39xUg97Iioa8C8BOttcuNAFqVUscs2K5l0qdkjlhWWteR0LaCP7bmzj4UVrVg3tZDScVmh2Trxw/Vd6C1qy+u1wRTEMdZTxzfO0pWzJ6iIrIYwM0AxolINYCnAYwFAKXUXACrAdwJoAxAF4CH7QrWjFTNCgQA976+PeJzRdUtOOPUMbg07YyUxWNV6fuWl7ZgwnmnYctvvxf3a0dbSurtH3Q6BKIhMRO6UuqBGM8rAI9aFlGS7EroCgp5lc04+7Sxpta/Z04g2Vc8e5ct8URjRVKtTHJCj9HirazDTodANGTUjeUSN91l8H1vDNeb9w7YVzLrONGP2vae4RAs3Ha0+tlD9R24dNzpFu7N/9p64quaIrITE3oMXSf6U77Pe17bhsMNkZsqVjR0Yt+xNtzxt4k39w+vr91Z3oR/eDMbM374tYS3SUTOYkI30KcrfW86UJfy/UdL5gBw66wt6B9UIdU5nSf6kX24MeF9ljcEbhIXVbckvA0ictaoG5zLjAqDhGrVDceZmSX43bLCuF4T3vjBqBnj/uPsYecEt45aSaMTE7rOif6BEcvi+bkero/dFPKtrHJ8mBvfsLxWJg0/tUPPKvXWMA5EdmNC1yzKrsBX/30t8iqbsP/4cDf8Q/WB0rqZPHjLrC32BGeD8FNEsoneiRPFx4VHU7/TMGw6Tm7COnTN29srAAA7y5txyKikbSJjRVqlpas3ichSK9mrASa45PnpKopSiyV0kxL9jW0rbcA109dbGosxZlKv4ydIyWJCt1n+kea41jea+SfeUu+D83MwEGH8l+DmrS5JOzH+iBtKskzCo1NZXYcr+yAwoRswShRmk0dbTx/6k+h0tNTghqm+Tt+st7eXR33eqoTe2t2HjBnrkVcZOHH1DQTeqO1lDXGPB6O3du8xNHakdkLlvMomdPeOvDFO1pv16QFP39S+ddYW/MPcbKfDGIEJXdPaHUg+CgrFSQy5e/UfPsVvlsbXLDFox+FGrC0+ntBrwxO0UU/WwUGFp1cZziSYsO+9+BkaOnrxx9X7hpa19/Thx/Nz8E+LchPe7i/ey8fDf9oVdZ0BpTAzswQlR5Nvslnb1oP73sjGb+JsUjoaHW/tMWwRFo/Zm8owaYG3JwNPpKBlNyZ0TVNn4Mbl82sPGH5Q8VQprCxIrPXFxHk7sGl/Yh2ZzLRaKTnWhvwj1nYcCr5vev1aKf1gXXJf+Orm6OPyrMivwVtZ5Zg4L1BS2n+8Dbe89NnQyTkeHVqP4H1xnhzMXOms3Xsca/cmdqJ2m/6BQdz4nxvxqyU88bkRE7pD6ttPYE+1NZNvuI1TVduvrC/FofpOfF7W4FAExn7xXh5+8Z4/JikZ0EoK60tqHY6EjDChm2T1DbjrZ27A38/ZZtn2jMbSXpRdEXFmpfDmiXYk4ZauPizPi96Jqq69B1NXFHEY2hTo6RtIuqqE3I0J3afaevow7aNiPPDWjrheZ3Xrl1/HuJ/wzKoSLN5ZZWmJL5VXCF7q+n/579fi757b7HQYZCMmdJNOJFiCjFWyt2swrOB+2xKoT46mf2AwZPCyIH1iM2p6GYkVzR2DVydWnIxc0BIyIWY7r9W1p7blEKUWE7pJC7ZFbwaYqI8SvIEKGN+QDBctQa3cXRN3ffNNz27CVdPWxfUau8VzAomlPMZIl1ap0413n6zN++twzfT1Kb93cOusLXhtY2lK90nRMaH7RKTCad/AIJ5dsx+dJ/pDrhZEgCeWFODB+Tlx7ae+/YRhk8g9NcM3eL8xY0PM7bR09YackJyeGDnRwn2kq4KBQYW7ZmdFrEq6YeZG09uKZVdFEwBgd1Vqhz4uq+vAS+sPpnSfFB3HcrGZnWObzNlUhqbOE3hl4rUR1+npG8TcLYcwqBT+/urzLdv31BV7cNX5f5Xw64PDIdyVxCQdkbihB2l7Tx+Kj7Yl3CchEVZeqVBkZUk2x7UTS+gOSybfL9xejpUFRzE4qEYMMRC+XatbkSzeeQT/vtLaTkrhzFQpASPr0J/8yx6kT8m0KyzXcWJANKevqJx0+ytZTocQERO6zXIr4xvLJRELtpXjmY9LYq6n/xEW+bQNPICEOhYlKlIudaKwnIp9Otmqp6alGx8V1Di2/yCjCWbcggndZlsPRh+vworSVakFl4CxkkGkwb6ssqGk1lel6uC7ZVfpueNE/9Awz15qOpmMH73xOR7/oCCpsZL8jgndYUYdgpxkFM6HuVX48pOrsXK3DaUjbX+JDpcQuinj93J5XnXMVkr6z+GX70fu1blk1xGkT8kcbroZ4/Oz69OdtCAHt7zknQlVrFDLJpcx8aaoD5gpobV190UshccaYTB4mfvEkoK4Y0uVlq5eZO45FrLsYG07tpc1DFVH/ezbl5ja1uo9kcdd+c81+wEAHT39OOf0UyKuZ3SDctCCq5yBQYWmzl7s1sbk2VXRhDmbywL7THrrsbmh7tz5CNyLJXSH2VWCe3Pr4ZC/V0QpXV8xbe3QY6OkP+iCK9ze/kG8m10Rsepni0HV1m0vbzV1b8EOw1Uuw59wtM/ArOfW7sf1M4ebhWYWDZ/EUllv70Q1j7uuZd2JJXQfsKLWZnl+5DFXsg83Jr+DCOrbzF1Gz91yCLPWH8QpY9xVBon11uufN9ubM1pi3hBliAQ3lJ5TIfz92XqwHoNK4eav/rUzAbkIE7rT4kzGyVy2L8qujPhccIKKRIc4MOt4aw9e2TDcGWWn1ikmlhZtsoz2nn5b4opXrE8hkUlSXHY7xXUivT8/WRgYV73i2btSGI07uau4MwrFe+l66ZOrRyz7YFeVqddGK4UH6WeR6RsYtKzlyeCgglIKT/1lj+l4/UCfhN7LiXxCtUIqq1zMXg3kVTZhh8VXeG66EvmkKPmb+VZiQneYm0tlVpaGL31yNR55Lx+DCWadWO9Tsq2F4n11cP1IuzVKOpWNxkMZW+XVjaX42tOxx9np6RvAY3/OR01L9AlEjJgpgCzNrcJuraPbfW9kY+K8+Eb8TGbfqfZxIRM66ZTXp2YwKPMSGzXRjLXFx5MuW3mmd/tQnKlNQsGZl6LZuK8OnxQdw8xMe24Y/3ZZEf73f31u/Ya1t9JN3wE3xQIwoTsu0TlE7aIvcW7YZ/2sNIn+AKxMi2V17Uifkont2uiEs9YfjLsFitnDsPsKzM1XeFaL91CLqluQMWO96ZvRyapq6oo5ObvdTCV0EbldRA6ISJmITDF4/qciUi8iBdq/n1sfKqWC/kfzb8v3WL792rbkho01qsoQQcSZmYwEx6AJXi7P3liK2SaGgS0+2jp0c/a5NfvRPzAYsRpgqNmi6ahMcnEC7xsYxH98Yk+pv6i6Je4b9nM2laGhoxc7Dpu78Z4I/bfxx/Nz8MzHJSk7gRiJ2cpFRE4G8DqAHwCoBrBLRFYppcI/uSVKqcdsiJF8JNGZ0oMl0T+u3m/4fGOH+R9R8Ace75gcr24YTvpLcqvwvcvTIq4bvBKxuwTt1CV/eH+A+VmHsa2sAZ8dMB7qovhoK646/6yE9/euroWW26o5gtp6Aid7J+Mz02zxBgBlSqnDACAiHwC4F4AzPTbIVl6c0UYpZ6oejrfGvtow8+Pu6u13bZKKJPxcOCNzX9T1yxs6k0royb099r25bvvczFS5XABA386sWlsW7j4RKRKRZSJykdGGRGSyiOSKSG59ffRBq4j0YrViMZvPC+KcBKKsrgMVEWYx+sPHJTFbuZg5QV4zfT2uMtE6xUgyJzK3JSOzzDZbTM1J3l1volU3RT8GkK6UuhrAegDvGK2klJqnlMpQSmWkpUW+XCUKF+23KQJ0xhiPBgiUhH/4+va49nvrrC24+cXPAAAtcQzLG0+yDB+r3u521skkukRf62STQ6+euBJhJqHXANCXuC/Ulg1RSjUqpYJFkfkAvmFNeOQHRxNo7xyPlq4+LN55JOZ6e2vaktrPwdro9f/BOtREpTrp1bb14AeztsT1+TiVHPX7NRtDKt5Pt50szCT0XQAuE5FLROQUABMBrNKvICL6ecTuARC9Qo1Glf/57KbkN2LDb7Ojpx89fbFL9mZD6B8Y/nXb9Ts3+zaUN3Rixiclhn0JKhoDVUj5R1pQWtdh6mToZeHvwO4jzZi0IGd4CGQfiZnQlVL9AB4DsA6BRP2hUqpYRKaLyD3aav8iIsUiUgjgXwD81K6Aiayytvg47ppt3XRi+mRrtlNWUbU9Ezv/06JczN9WjuxDI7vdP7/2gKX72n0k9qxcydZn66uhku0D8JulhcgqbUBlY/Kd+vSxRPvIM4uOIX1Kpu1Xq6YG51JKrQawOmzZNN3jqQCmWhsa0TArLp+Nkuwhkz11j7Z0o7lrZJWKPqpgAvn8UAO+OPZkU9tt1M2b2p5Alc3b2ysMlwfHuH9wfk7MQatinXtaunohEJx12ljD5yP1CtWP4WLlBVa8PZgjrW5XdYnRiWRZXqBdyf7jbTj/7C/as2NwtEUiU8xUGwVPOg++lZNQibTCwrFe9GPmpE/JxJwHr014W9dMXw8AuPea80011QzSj+GSdIsTZfgwKv0+u3sHMHN1Cf7t9sstnSVs0/46nOgfwKljzJ3A7caETq5XUNWCuVsOpXSflY2dmHDe6THXe1k3FLC+GGq69BdhvSW7jgz11P1y2ulIP+90LPjp9SY3OtJjf94d9fmBQYVVhTW49+sX4KSTjBPeRxZME5goo7eptLYdT2m9fqO/VmFRdgXe23EEZ35hrG65NTp6+nHqGcMJPdpnvyi7Er/6sBAF026zaO+hmNDJ9ZyY6X1G5j58zURHGH0Hmwh5MMbrjX/9+mEXDtV3mq4aCoo3lEXZFXjm4xJ09w7iwW9eHOer7WdUzTIjcx92lkfu1q+vpgv2ClbKvtETohX8g1cFkXrSWoWDc5HrWVXXGc9mlAorfZuQyKV8vC0tWrvNDWkcTywKCvVaB6imTrt6CluXRuP9PujXl0SuomJtP+zvSQtzrNlwApjQadSIb1zu+H/tiaSsVzbEHhRMr6HD+oT7+uZDI8bYUUphZmYJDiQ49k645Fu5JLJT3eu17C0GsSzLq446CUd7Tx/WhE1AHo1Rf4dU9TBgQidXS5+Sia5ed0w7F0tpXUdcMzwNDCrDwcqsKDnGm0A37a8DEBh0DAAaOnrxVlY5fjzfqskpLKRC/jO7eiAOGX5/g00hf7O0MOrJ/rdLi/DI+/mx92MQ0MZ9tfjl+3kmI00e69DJ9RKZWSdZiSTVF9fF177brjboQOIl4qqmwHttx/ADnSYm34gkkc8jtF9AcJmgtK4jrm1WtyTe+uhn7+QCAG69InQCa6WUpa1tglhCJ9fbXmbtnJRmJDJV3jZtwgyzqpqNT1RNFoynbV23d2u2IyJ46VNz9yQO1rbjswN1EZ8PnmzCI/u48Kg2cuXIzy5TqzLR59C2sLF51hUfR/qUzJACxCPv5SU9ZEQqMaETGYhzqPSE7IlQQn/47V2Gy+Mp4VrZ7tsq3SaHWbjt5a34adh7EN4j88PcqqEhDIL+/+LduHLaOry2qQwAkF/ZrK0/XLWlf1v+cd4ODOo+6KW5gUnU99a0AgByK5qwZm/sGcUyZmzA1BWhk8FMXVEU9TV2dWpiQidyyFtZ8U1X9vgHBTZFEplVtQKB+yCJZzF9qVsB+N2yooiTbn9ceBRbDtbjqFEnqLADWqibMi74VHBX98/NNh3f4p1H0Kor8S/eWRW2Ruh+7SovsA6dyIAdrUmSdbzN/L0EtxXQF2VX4itfOmPE8nd3VOJLZ55qaTwKwEMLdxo+F/6+LM+vMXjOZUMoxoEJnchA8VH31Zs2tJuvW7fqhptVNfF5lc3Iqxw5iNfvTfT0DBdrLJcy7aankfC3Rb+t8BK6nQL75U1RolHruMkJttt7+pIvobutkJpEPCEdi6K8M8Hn3Hbo8WBCJ/KZ3y0rSqrwN2v9waEqJyfmatUrrW3HqxtKQ5pRfmPGhri2Ea0Jpr41U712zHaczDbsqw2LyR6sciHymerm7qRK6LM3luLT4kDrjto2Z+8l3D83G63dffjOVxKfsvJflxQOPQ4fb0efvI2qhOzCVi5ElDJmmxjaGkPvwNAY8a0WtM0HDOrQDdaxe05XO7GETuQze7R21MlwQx36FdPWDj0urE7+mIwY3WD90/YKNLTbe2Vi10mDCZ2IRvByKTWa8NY/Rieu3Mpm5Npc/cIqFyJKmfYebwyIFq8/54ROiO230xYTOhGN0GIwf6ofhA/0Fu/8pG7nyYQ+4bzTnA6BiHwgFWP2pJInE/qkGyc4HQIR+cCRJusm5o4H69B17rvuQqdDICKKauXuyHPh2nXT2ZMJ/ZzTT3E6BCKiqJ5YkvrRMT2Z0ImIvIxVLkREPnGg1prJt8MxoRMRpdjS3PAJMKzBhE5E5BNM6EREKVZv01gxTOhERCm2YV+dLdtlQici8glTCV1EbheRAyJSJiJTDJ4/VUSWaM/niEi61YGGu/WKv7Z7F0REnhIzoYvIyQBeB3AHgCsBPCAiV4at9jMAzUqp/wHgZQDPWR1ouAduuNjuXRAReYqZEvoNAMqUUoeVUr0APgBwb9g69wJ4R3u8DMAtYtW04xFkTDgXZ31xLN748XWYdOMEnDqGtUdENLqZmeDiAgD6RpPVAL4ZaR2lVL+ItAI4D0CDfiURmQxgMgBcfHFyJeyzThuLwqdvAwDc8bfj8R8//BoGBhW2HKxDXdsJfP2is1Hb1oPath6sK67Fl9NOx1tZ5bjp0vOQfbgxqX0TESXjn79zqS3bTemMRUqpeQDmAUBGRoblnV9PPknw/cu/NPT3FeP/CgDwj9cHTh5P3RVeU0RE5B9m6ilqAFyk+/tCbV+sXUwAAAVxSURBVJnhOiIyBsBZAFgMJiJKITMJfReAy0TkEhE5BcBEAKvC1lkF4CHt8f0ANim/TQVCRORyMatctDrxxwCsA3AygIVKqWIRmQ4gVym1CsACAO+KSBmAJgSSPhERpZCpOnSl1GoAq8OWTdM97gHwI2tDIyKieLCtHxGRTzChExH5BBM6EZFPMKETEfmEONW6UETqAVQm+PJxCOuF6mE8Fnfyy7H45TgAHkvQBKVUmtETjiX0ZIhIrlIqw+k4rMBjcSe/HItfjgPgsZjBKhciIp9gQici8gmvJvR5TgdgIR6LO/nlWPxyHACPJSZP1qETEdFIXi2hExFRGCZ0IiKf8FxCjzVhtVNEZKGI1InIXt2yc0VkvYiUav+foy0XEZmtHUORiFyne81D2vqlIvKQbvk3RGSP9prZdk3xJyIXichmESkRkWIRedzDx/IFEdkpIoXasTyjLb9Em8y8TJvc/BRtecTJzkVkqrb8gIj8L93ylH0fReRkEdktIp94/DgqtM+/QERytWWe+35p+zpbRJaJyH4R2SciNzl6LEopz/xDYPjeQwAuBXAKgEIAVzodlxbbdwBcB2CvbtnzAKZoj6cAeE57fCeANQAEwI0AcrTl5wI4rP1/jvb4HO25ndq6or32DpuOYzyA67THZwI4iMDk4F48FgFwhvZ4LIAcbb8fApioLZ8L4BHt8S8BzNUeTwSwRHt8pfZdOxXAJdp38ORUfx8B/ArAnwF8ov3t1eOoADAubJnnvl/avt4B8HPt8SkAznbyWGw5SBvfvJsArNP9PRXAVKfj0sWTjtCEfgDAeO3xeAAHtMdvAnggfD0ADwB4U7f8TW3ZeAD7dctD1rP5mD4C8AOvHwuA0wDkIzAfbgOAMeHfKQTG/L9JezxGW0/Cv2fB9VL5fURgprCNAL4P4BMtLs8dh7b9CoxM6J77fiEwM1s5tMYlbjgWr1W5GE1YfYFDsZjxJaXUMe3xcQDBCU8jHUe05dUGy22lXapfi0DJ1pPHolVTFACoA7AegZJoi1Kq32D/IZOdAwhOdh7vMdrhFQC/AzCo/X0evHkcAKAAfCoieRKYOB7w5vfrEgD1AN7WqsLmi8jpcPBYvJbQPUsFTrGeaSMqImcAWA7gCaVUm/45Lx2LUmpAKXUNAiXcGwBc7nBIcRORuwHUKaXynI7FIt9WSl0H4A4Aj4rId/RPeuj7NQaBatY3lFLXAuhEoIplSKqPxWsJ3cyE1W5SKyLjAUD7v05bHuk4oi2/0GC5LURkLALJ/H2l1AptsSePJUgp1QJgMwLVC2dLYDLz8P1Hmuw83mO02rcA3CMiFQA+QKDa5VUPHgcAQClVo/1fB+AvCJxovfj9qgZQrZTK0f5ehkCCd+5Y7Kons6nOagwCNwwuwfDNm6ucjksXXzpC69BfQOjNkee1x3ch9ObITm35uQjUyZ2j/SsHcK72XPjNkTttOgYBsAjAK2HLvXgsaQDO1h5/EUAWgLsBLEXozcRfao8fRejNxA+1x1ch9GbiYQRuJKb8+wjgZgzfFPXccQA4HcCZusefA7jdi98vbV9ZAL6qPf6DdhyOHYttXzwb38A7EWh5cQjAU07Ho4trMYBjAPoQOHP/DIF6y40ASgFs0H1IAuB17Rj2AMjQbef/ASjT/j2sW54BYK/2mjkIuxFj4XF8G4FLxCIABdq/Oz16LFcD2K0dy14A07Tll2o/lDIEkuKp2vIvaH+Xac9fqtvWU1q8B6BraZDq7yNCE7rnjkOLuVD7Vxzclxe/X9q+rgGQq33HViKQkB07Fnb9JyLyCa/VoRMRUQRM6EREPsGETkTkE0zoREQ+wYROROQTTOhERD7BhE5E5BP/DSfn8QU4eobHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wueUr_kueVwW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyc17H6rwtuy"
      },
      "source": [
        "## Validation Loop\n",
        "Compute Validation Error on the final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oROxs8Kw7Wq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnYglK5qw8aE"
      },
      "source": [
        "## Visualize Some Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v56i0OfKxAIo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}